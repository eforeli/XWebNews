#!/usr/bin/env python3
"""
Free Tier å°ˆç”¨çˆ¬èŸ² - æ¯æ—¥1å€‹è³½é“ï¼Œ7å¤©å®Œæ•´è¼ªæ›¿
é©æ‡‰ 1æ¬¡è«‹æ±‚/15åˆ†é˜ çš„åš´æ ¼é™åˆ¶
"""

import tweepy
import json
import csv
import time
from datetime import datetime, timedelta
from typing import List, Dict, Any
import logging
import os

class FreeTierWeb3Crawler:
    def __init__(self, bearer_token: str):
        """Free Tierå°ˆç”¨ - æ¯æ—¥å–®è³½é“çˆ¬èŸ²"""
        self.client = tweepy.Client(bearer_token=bearer_token)
        self.setup_logging()
        
        # 7å€‹Web3è³½é“è¼ªæ›¿é †åº
        self.web3_rotation = [
            ("DeFi", "DeFi"),
            ("Layer1_Layer2", "Ethereum"), 
            ("NFT_GameFi", "NFT"),
            ("AI_Crypto", "AI"),
            ("RWA", "RWA"),
            ("Meme_Coins", "DOGE"),
            ("Infrastructure", "Chainlink")
        ]
        
        # ç‹€æ…‹æ–‡ä»¶
        self.state_file = "free_tier_rotation_state.json"

    def setup_logging(self):
        """è¨­ç½®æ—¥èªŒ"""
        timestamp = datetime.now().strftime("%Y%m%d")
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler(f'free_tier_{timestamp}.log'),
                logging.StreamHandler()
            ]
        )
        self.logger = logging.getLogger(__name__)

    def get_today_category(self) -> tuple:
        """ç²å–ä»Šæ—¥è¦çˆ¬çš„è³½é“"""
        
        # è®€å–è¼ªæ›¿ç‹€æ…‹
        if os.path.exists(self.state_file):
            try:
                with open(self.state_file, 'r') as f:
                    state = json.load(f)
            except:
                state = {"rotation_index": 0, "last_crawl_date": None}
        else:
            state = {"rotation_index": 0, "last_crawl_date": None}
        
        today = datetime.now().strftime("%Y-%m-%d")
        
        # å¦‚æœä»Šå¤©å·²ç¶“çˆ¬éï¼Œè¿”å›ä»Šå¤©çš„è³½é“
        if state.get("last_crawl_date") == today:
            current_index = state["rotation_index"]
            category, keyword = self.web3_rotation[current_index]
            self.logger.info(f"ğŸ“… ä»Šæ—¥å·²çˆ¬å–: {category}")
            return category, keyword, False  # Falseè¡¨ç¤ºä»Šå¤©å·²çˆ¬é
        
        # é¸æ“‡ä»Šæ—¥è³½é“
        current_index = state["rotation_index"]
        category, keyword = self.web3_rotation[current_index]
        
        # æ›´æ–°ç‹€æ…‹
        next_index = (current_index + 1) % len(self.web3_rotation)
        state.update({
            "rotation_index": next_index,
            "last_crawl_date": today,
            "today_category": category
        })
        
        # ä¿å­˜ç‹€æ…‹
        with open(self.state_file, 'w') as f:
            json.dump(state, f, indent=2)
        
        self.logger.info(f"ğŸ“… ä»Šæ—¥é¸å®šè³½é“: {category} (é—œéµå­—: {keyword})")
        self.logger.info(f"ğŸ”„ æ˜æ—¥å°‡çˆ¬å–: {self.web3_rotation[next_index][0]}")
        
        return category, keyword, True  # Trueè¡¨ç¤ºéœ€è¦çˆ¬å–

    def crawl_single_category_free_tier(self, category: str, keyword: str) -> List[Dict[str, Any]]:
        """Free Tierå®‰å…¨çˆ¬å– - åªç”¨1æ¬¡APIè«‹æ±‚"""
        
        self.logger.info(f"ğŸ¯ Free Tierçˆ¬å–: {category}")
        self.logger.info("âš ï¸ ä½¿ç”¨1æ¬¡APIè«‹æ±‚ï¼Œç²å–æœ€å¤§æ•¸é‡æ¨æ–‡")
        
        try:
            query = f"{keyword} -is:retweet lang:en"
            self.logger.info(f"   æŸ¥è©¢: {query}")
            
            # ä½¿ç”¨æœ€å¤§max_results=100ä¾†å……åˆ†åˆ©ç”¨é€™1æ¬¡è«‹æ±‚
            response = self.client.search_recent_tweets(
                query=query,
                tweet_fields=['created_at', 'author_id', 'public_metrics'],
                user_fields=['username', 'verified', 'public_metrics'],
                expansions=['author_id'],
                max_results=100  # Free tierè¦å……åˆ†åˆ©ç”¨æ¯æ¬¡è«‹æ±‚
            )
            
            if not response or not response.data:
                self.logger.warning(f"âš ï¸ {category}: ç„¡æ¨æ–‡çµæœ")
                return []
            
            # è™•ç†ç”¨æˆ¶ä¿¡æ¯
            users = {}
            if hasattr(response, 'includes') and response.includes and 'users' in response.includes:
                users = {user.id: user for user in response.includes['users']}
            
            tweets_data = []
            
            # è™•ç†æ¨æ–‡
            for tweet in response.data:
                author = users.get(tweet.author_id)
                metrics = tweet.public_metrics or {}
                
                # è¨ˆç®—äº’å‹•åˆ†æ•¸
                engagement_score = (
                    metrics.get('like_count', 0) * 1 +
                    metrics.get('retweet_count', 0) * 2 +
                    metrics.get('reply_count', 0) * 0.5
                )
                
                tweet_data = {
                    'category': category,
                    'tweet_id': tweet.id,
                    'text': tweet.text,
                    'created_at': tweet.created_at.isoformat() if tweet.created_at else None,
                    'author_id': tweet.author_id,
                    'username': getattr(author, 'username', 'unknown') if author else 'unknown',
                    'verified': getattr(author, 'verified', False) if author else False,
                    'retweet_count': metrics.get('retweet_count', 0),
                    'like_count': metrics.get('like_count', 0),
                    'reply_count': metrics.get('reply_count', 0),
                    'quote_count': metrics.get('quote_count', 0),
                    'engagement_score': engagement_score,
                    'url': f"https://twitter.com/{getattr(author, 'username', 'unknown') if author else 'unknown'}/status/{tweet.id}"
                }
                tweets_data.append(tweet_data)
            
            # æŒ‰äº’å‹•åº¦æ’åºï¼Œå–å‰30æ¢ç²¾é¸
            tweets_data.sort(key=lambda x: x['engagement_score'], reverse=True)
            tweets_data = tweets_data[:30]  # ç²¾é¸30æ¢
            
            self.logger.info(f"âœ… {category}: æˆåŠŸç²å¾— {len(tweets_data)} æ¢ç²¾é¸æ¨æ–‡")
            return tweets_data
            
        except tweepy.TooManyRequests:
            self.logger.error(f"âŒ {category}: APIé™åˆ¶ - Free tieræ¯15åˆ†é˜åªèƒ½1æ¬¡è«‹æ±‚")
            return []
        except Exception as e:
            self.logger.error(f"âŒ {category}: éŒ¯èª¤ - {str(e)}")
            return []

    def run_daily_free_tier_crawl(self) -> Dict[str, List[Dict[str, Any]]]:
        """åŸ·è¡ŒFree Tieræ¯æ—¥çˆ¬å–"""
        
        self.logger.info("ğŸ†“ Free Tieræ¯æ—¥Web3çˆ¬å–")
        self.logger.info("ğŸ¯ ç­–ç•¥: æ¯æ—¥1å€‹è³½é“ï¼Œ7å¤©å®Œæ•´è¼ªæ›¿")
        
        # ç²å–ä»Šæ—¥è³½é“
        category, keyword, need_crawl = self.get_today_category()
        
        if not need_crawl:
            self.logger.info("âœ… ä»Šæ—¥å·²å®Œæˆçˆ¬å–")
            # å˜—è©¦è¼‰å…¥ä»Šæ—¥çµæœ
            try:
                today = datetime.now().strftime("%Y%m%d")
                json_files = [f for f in os.listdir('.') if f.startswith(f'free_tier_{today}') and f.endswith('.json')]
                if json_files:
                    latest_file = sorted(json_files)[-1]
                    with open(latest_file, 'r', encoding='utf-8') as f:
                        return json.load(f)
            except:
                pass
            return {category: []}
        
        # åŸ·è¡Œçˆ¬å–
        tweets = self.crawl_single_category_free_tier(category, keyword)
        
        # æ§‹å»ºçµæœ - ç‚ºä¿æŒçµæ§‹ä¸€è‡´æ€§ï¼ŒåŒ…å«æ‰€æœ‰è³½é“
        all_tweets = {}
        for cat_name, _ in self.web3_rotation:
            all_tweets[cat_name] = tweets if cat_name == category else []
        
        self.logger.info(f"ğŸ‰ ä»Šæ—¥Free Tierçˆ¬å–å®Œæˆ")
        self.logger.info(f"ğŸ“Š {category}: {len(tweets)} æ¢æ¨æ–‡")
        
        return all_tweets

    def save_results(self, data: Dict[str, List[Dict[str, Any]]], category: str):
        """ä¿å­˜çµæœ"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # JSON ä¿å­˜
        json_filename = f"free_tier_{timestamp}.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        # CSV ä¿å­˜ (åªä¿å­˜ä»Šæ—¥çˆ¬å–çš„è³½é“)
        today_tweets = data.get(category, [])
        if today_tweets:
            csv_filename = f"free_tier_{timestamp}.csv"
            with open(csv_filename, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=today_tweets[0].keys())
                writer.writeheader()
                writer.writerows(today_tweets)
        
        self.logger.info(f"ğŸ’¾ çµæœå·²ä¿å­˜: {json_filename}")
        return json_filename

def main():
    BEARER_TOKEN = "AAAAAAAAAAAAAAAAAAAAAF833wEAAAAAVK2bhuSiu%2FaikoUWzmEQvdS%2BJhE%3DjNPAILRXsZOyy1waEYDjahABCRLjG8d9LLyLMAF0CQ3LCckCPq"
    
    print("ğŸ†“ Free Tier Web3çˆ¬èŸ²")
    print("=" * 50)
    print("ğŸ“‹ é©æ‡‰ç­–ç•¥: æ¯æ—¥1å€‹è³½é“ï¼Œ7å¤©å®Œæ•´è¦†è“‹")
    print("âš¡ APIé™åˆ¶: 1æ¬¡è«‹æ±‚/15åˆ†é˜")
    print("ğŸ¯ æ¯æ¬¡ç²å–: 30æ¢ç²¾é¸æ¨æ–‡")
    print("=" * 50)
    
    crawler = FreeTierWeb3Crawler(BEARER_TOKEN)
    
    # åŸ·è¡Œçˆ¬å–
    results = crawler.run_daily_free_tier_crawl()
    
    # æ‰¾å‡ºä»Šæ—¥çˆ¬å–çš„è³½é“
    today_category = None
    today_count = 0
    for category, tweets in results.items():
        if tweets:
            today_category = category
            today_count = len(tweets)
            break
    
    if today_category:
        # ä¿å­˜çµæœ
        filename = crawler.save_results(results, today_category)
        
        # é¡¯ç¤ºçµæœæ‘˜è¦
        print(f"\nğŸ“Š Free Tieræ¯æ—¥çˆ¬å–çµæœ:")
        print(f"   ğŸ¯ ä»Šæ—¥è³½é“: {today_category}")
        print(f"   ğŸ“ˆ æ¨æ–‡æ•¸é‡: {today_count}")
        
        if today_count > 0:
            avg_engagement = sum(t.get('engagement_score', 0) for t in results[today_category]) / today_count
            print(f"   ğŸ’« å¹³å‡äº’å‹•åº¦: {avg_engagement:.1f}")
        
        print(f"\nâœ… Free Tierç­–ç•¥é‹è¡ŒæˆåŠŸï¼")
        print(f"ğŸ“… æ˜æ—¥å°‡è‡ªå‹•è¼ªæ›¿åˆ°ä¸‹ä¸€å€‹è³½é“")
        print(f"ğŸ”„ 7å¤©å¾Œå®Œæ•´è¦†è“‹æ‰€æœ‰Web3è³½é“")
        
    else:
        print("âš ï¸ ä»Šæ—¥å·²å®Œæˆçˆ¬å–æˆ–é‡åˆ°å•é¡Œ")

if __name__ == "__main__":
    main()